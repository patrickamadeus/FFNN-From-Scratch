{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NN** Implementation (Forward + Backward Propagation)\n",
    "1. Add input in /test/input and model in /test/model with .txt format, makesure they both have the same filename.\n",
    "2. Input the filename for both the input and the model, ensuring that they have the same filename.\n",
    "3. Scroll down and click on `./tmp/network.html`. This will redirect you to network.html, which you can then open the visualization using a live server.\n",
    "\n",
    "#### Made by:\n",
    "- Samuel Christoper Swandi - 13520075\n",
    "- Grace Claudia - 13520078\n",
    "- Ubaidillah Ariq Prathama - 13520085\n",
    "- Patrick Amadeus Irawan - 13520109\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of Content\n",
    "\n",
    "1. [Library & Dependencies](#library)\n",
    "2. [Helper Function](#helper)\n",
    "3. [Neural Network Visualization](#visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library & Dependencies <a name=\"library\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install pyvis==0.3.2\n",
    "!python3 -m pip install networkx==2.6.3\n",
    "!python3 -m pip install numpy==1.21.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Class**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedLayer:\n",
    "    def __init__(self, input_size, output_size, weights):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.weights = weights[1:]\n",
    "        self.bias = weights[0]\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.dot(input, self.weights) + self.bias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationLayer:\n",
    "    def __init__(self, activation):\n",
    "        self.activation = activation\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return self.activation(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        complete_result = []\n",
    "        output = x[:, 1:]\n",
    "\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "            if isinstance(layer, ActivationLayer):\n",
    "                complete_result.append(output)\n",
    "\n",
    "        return complete_result[-1] , complete_result\n",
    "\n",
    "    # train the network\n",
    "    def fit(self, x_train, y_train, learning_rate=0.1, epochs = 5, batch_size = 2, err_threshold = 0.01):\n",
    "        # training loop\n",
    "        for i in range(epochs):\n",
    "            print(i)\n",
    "            err = 0\n",
    "            for j in range(len(x_train)):\n",
    "                \n",
    "                # forward propagation\n",
    "                output = x_train[:, 1:]\n",
    "                for layer in self.layers:\n",
    "                    output = layer.forward(output)\n",
    "\n",
    "                print(output)\n",
    "                # compute loss (for display purpose only)\n",
    "                # err += self.loss(y_train[j], output)\n",
    "\n",
    "            #     # backward propagation\n",
    "            #     error = self.loss_prime(y_train[j], output)\n",
    "            #     for layer in reversed(self.layers):\n",
    "            #         error = layer.backward_propagation(error, learning_rate)\n",
    "\n",
    "            # # calculate average error on all samples\n",
    "            # err /= samples\n",
    "            # print('epoch %d/%d   error=%f' % (i+1, epochs, err))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Helper** Function <a class=\"anchor\" id=\"helper\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(net):\n",
    "    return net\n",
    "\n",
    "def ReLU(net):\n",
    "    return np.maximum(0,net)\n",
    "\n",
    "def sigmoid(net):\n",
    "    return 1/(1+np.exp(-net))\n",
    "\n",
    "def softmax(net):\n",
    "    res = []\n",
    "    for sample in net:\n",
    "        res.append(np.exp(sample)/np.sum(np.exp(sample)))\n",
    "    return np.array(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.square(y_true - y_pred))\n",
    "\n",
    "def sse(y_true, y_pred):\n",
    "    return np.sum(np.square(y_true - y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(data):\n",
    "    '''\n",
    "    Function to load model from file\n",
    "    INPUT :     data -> data from model file\n",
    "\n",
    "    OUTPUT :    weights -> weights of each model neuron\n",
    "                list_prev_size -> list of previous layer size\n",
    "                list_layer_size -> list of current layer size\n",
    "                list_activation -> list of activation function\n",
    "    '''\n",
    "\n",
    "    idx = 1\n",
    "    weights,list_prev_size,list_layer_size,list_activation = [],[],[],[]\n",
    "\n",
    "    for i in range(int(data[0]) - 1):\n",
    "        # Loading size & act function\n",
    "        prev_size, layer_size, activation = [int(i) for i in data[idx].split()]\n",
    "        list_prev_size.append(prev_size)\n",
    "        list_layer_size.append(layer_size)\n",
    "        list_activation.append(activation)\n",
    "        \n",
    "        # Loading weights\n",
    "        idx += 1\n",
    "        weight = []\n",
    "        for j in range(prev_size + 1):\n",
    "            weight.append([float(i) for i in data[idx].split()])\n",
    "            idx += 1\n",
    "        weights.append(weight)\n",
    "    \n",
    "    return weights, list_prev_size, list_layer_size, list_activation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Output Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(x, net):\n",
    "    '''\n",
    "    Function to predict output from input data\n",
    "    INPUT :     x-> input data\n",
    "                net -> NeuralNetwork object\n",
    "\n",
    "    OUTPUT :    out -> output of the model\n",
    "                complete_out -> complete output of the model, visualization purpose\n",
    "                x -> input data, visualization purpose\n",
    "    '''\n",
    "    # Predict output\n",
    "    out, complete_out = net.predict(x)\n",
    "\n",
    "    # Gather complete output\n",
    "    n_complete_out = []\n",
    "    for i in range(len(complete_out[0])):\n",
    "        n_complete_out.append([complete_out[0][i], complete_out[-1][i]])\n",
    "\n",
    "    complete_out = n_complete_out\n",
    "    return out, complete_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSE Errors Function + microhelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_out_and_errors(output_data, out):\n",
    "    '''\n",
    "    Function to calculate output error\n",
    "    INPUT :     output_data -> output data from output file\n",
    "                out -> output of the model, obtained from predict_output function\n",
    "\n",
    "    OUTPUT :    out_pred -> output of the model (flattened)\n",
    "                out_true -> output from output_data (flattened)\n",
    "                sse_error -> sum squared error\n",
    "                sse_error <= max_sse -> boolean value, True if sse_error <= max_sse, False otherwise\n",
    "    '''\n",
    "    # Assign y_train from output_data\n",
    "    parsed_output = [[float(j) for j in i.split()] for i in output_data]\n",
    "    out_pred = out.flatten()\n",
    "    out_true = np.array(parsed_output[:-1]).flatten()\n",
    "    max_sse = parsed_output[-1][0]\n",
    "\n",
    "    return out_pred, out_true, sse(out_true, out_pred), sse(out_true, out_pred) <= max_sse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load** Section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FOLDER = '../test/model/'\n",
    "INPUT_FOLDER = '../test/input/'\n",
    "OUTPUT_FOLDER = '../test/output/'\n",
    "# read file from test folder\n",
    "def read_file(folder_path, file_name):\n",
    "    with open(folder_path + file_name, 'r') as file:\n",
    "        data = [i.rstrip(\"\\n\") for i in file.readlines()]\n",
    "    return data\n",
    "\n",
    "filename = input('Enter test case name (with extension): ')\n",
    "data = read_file(MODEL_FOLDER, filename)\n",
    "input_data = read_file(INPUT_FOLDER, filename)\n",
    "\n",
    "try: \n",
    "    output_data = read_file(OUTPUT_FOLDER, filename)\n",
    "except:\n",
    "    output_data = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Model Information---\n",
      "Number of layers : 3\n",
      "Input size : 2\n",
      "Output size : 2\n",
      "\n",
      "Weights : [[[0.35, 0.35], [0.15, 0.25], [0.2, 0.3]], [[0.6, 0.6], [0.4, 0.5], [0.45, 0.55]]]\n",
      "Previous layer size : [2, 2]\n",
      "Current layer size : [2, 2]\n",
      "Activation function : [2, 2]\n"
     ]
    }
   ],
   "source": [
    "weights, list_prev_size, list_layer_size, list_activation = model_load(data)\n",
    "\n",
    "print('---Model Information---')\n",
    "print('Number of layers :', len(list_prev_size) + 1)\n",
    "print('Input size :', list_prev_size[0])\n",
    "print('Output size :', list_layer_size[-1])\n",
    "\n",
    "print()\n",
    "print('Weights :', weights)\n",
    "print('Previous layer size :', list_prev_size)\n",
    "print('Current layer size :', list_layer_size)\n",
    "print('Activation function :', list_activation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build NN model\n",
    "act = {0: linear, 1: ReLU, 2: sigmoid, 3: softmax}\n",
    "net = NeuralNetwork()\n",
    "for i in range (int(data[0]) - 1):\n",
    "    net.add(ConnectedLayer(list_prev_size[i], list_layer_size[i], weights[i]))\n",
    "    net.add(ActivationLayer(act[list_activation[i]]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Predict** Section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign x_train from input_data\n",
    "x_train = []\n",
    "for i in range(len(input_data)):\n",
    "    x_train.append([float(i) for i in input_data[i].split()])\n",
    "x_train = np.array(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Prediction Information---\n",
      "Input data : [[1.   0.05 0.1 ]]\n",
      "Output data : [0.75136507 0.77292847]\n"
     ]
    }
   ],
   "source": [
    "out, complete_out = predict_output(x_train, net)\n",
    "\n",
    "# Print the information, complete with brief verbose\n",
    "print('---Prediction Information---')\n",
    "print('Input data :', x_train)\n",
    "print('Output data :', out.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[[0.75136507 0.77292847]]\n",
      "1\n",
      "[[0.75136507 0.77292847]]\n",
      "2\n",
      "[[0.75136507 0.77292847]]\n",
      "3\n",
      "[[0.75136507 0.77292847]]\n",
      "4\n",
      "[[0.75136507 0.77292847]]\n"
     ]
    }
   ],
   "source": [
    "net.fit(x_train,out_true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Error with **Sum Squared Error (SSE)**\n",
    "\n",
    "Sum Squared Error (SSE) is a mathematical function used in statistics and machine learning to measure the difference between predicted and actual values. It is commonly used as a cost function in various optimization algorithms, such as gradient descent.\n",
    "\n",
    "The SSE is calculated by taking the difference between each predicted value and its corresponding actual value, squaring the difference, and then summing all of the squared differences:\n",
    "\n",
    "$$SSE = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "Where:\n",
    "- $n$ is the number of data points\n",
    "- $y_i$ is the actual value of the i-th data point\n",
    "- $\\hat{y}_i$ is the predicted value of the i-th data point\n",
    "\n",
    "The SSE gives an indication of how well the model fits the data. A lower SSE indicates that the model is a better fit for the data.\n",
    "\n",
    "In machine learning, the SSE is often used as a cost function to be minimized during training of a model. The goal is to find the set of model parameters that minimizes the SSE, thus improving the accuracy of the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output prediction : [0.75136507 0.77292847]\n",
      "Output true : [0.01 0.99]\n",
      "SSE  :  0.5967422175200054\n",
      "sse <= max_sse  : False\n"
     ]
    }
   ],
   "source": [
    "out_pred, out_true, sse_err, isLessThanMaxSSE = compute_out_and_errors(output_data, out)\n",
    "\n",
    "print('Output prediction :', out_pred)\n",
    "print('Output true :', out_true)\n",
    "print('SSE  : ', sse_err)\n",
    "print(\"sse <= max_sse  :\", isLessThanMaxSSE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Visualization with **Pyvis**\n",
    "\n",
    "Pyvis is a Python library that provides an easy-to-use interface for visualizing complex networks, including neural networks. Implementation of the visualization is enlisted below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_network(data, complete_out) -> Network:\n",
    "    n = int(data[0])\n",
    "\n",
    "    # Constant\n",
    "    XSTEP, YSTEP, SIZE = 300, 300, 10\n",
    "\n",
    "    # Nodes\n",
    "    nodes = []\n",
    "    node_i = 1\n",
    "\n",
    "    # Nodes Value\n",
    "    value = []\n",
    "    x_val = 0\n",
    "    y_val = 0\n",
    "\n",
    "    # Position\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    # Styling + Text\n",
    "    label = []\n",
    "    color = []\n",
    "    edge = []\n",
    "    title = []\n",
    "\n",
    "    # Indexing\n",
    "    src_idx = 0\n",
    "    idx = 1\n",
    "\n",
    "    for i_layer in range(n - 1):\n",
    "        n_curr, n_next, _ = [int(i) for i in data[idx].split()]\n",
    "\n",
    "        if i_layer == 0:  # means that this is the first layer, hence construct input\n",
    "            for i_node in range(n_curr + 1):\n",
    "                if i_node == 0:  # bias\n",
    "                    color.append(\"#dd4b39\")\n",
    "                    label.append(\"Input[bias]\")\n",
    "                    temp = \"\"\n",
    "                    for i in range (len(input_data)):\n",
    "                        temp += str(x_train[i][0])\n",
    "                        if i < len(input_data) - 1:\n",
    "                            temp += \", \"\n",
    "                    title.append(temp)\n",
    "                else:\n",
    "                    color.append(\"#162347\")\n",
    "                    label.append(\"Input[{}]\".format(i_node))\n",
    "                    temp = \"\"\n",
    "                    for i in range (len(input_data)):\n",
    "                        temp += str(x_train[i][i_node])\n",
    "                        if i < len(input_data) - 1:\n",
    "                            temp += \", \"\n",
    "                    title.append(temp)\n",
    "                value.append(SIZE)\n",
    "                x.append(x_val)\n",
    "                y.append(y_val)\n",
    "                y_val += YSTEP\n",
    "                nodes.append(node_i)\n",
    "                node_i += 1\n",
    "            x_val += XSTEP\n",
    "\n",
    "        y_val = 0\n",
    "        # always construct the next layer\n",
    "        for i_node in range(n_next + 1):\n",
    "            if i_node == 0:\n",
    "                if i_layer == n - 2:\n",
    "                    continue\n",
    "                color.append(\"#dd4b39\")\n",
    "                label.append(\"HL{}[bias]\".format(i_layer + 1))\n",
    "                temp = \"\"\n",
    "                for i in range (len(input_data)):\n",
    "                    temp +=  \"1\"\n",
    "                    if i < len(input_data) - 1:\n",
    "                        temp += \", \"\n",
    "                title.append(temp)\n",
    "            else:\n",
    "                color.append(\"#162347\")\n",
    "                if i_layer == n - 2:\n",
    "                    label.append(\"Output[{}]\".format(i_node))\n",
    "                else:\n",
    "                    label.append(\"HL{}[{}]\".format(i_layer + 1, i_node))\n",
    "                temp = \"\"\n",
    "                for i in range (len(input_data)):\n",
    "                    temp += str(complete_out[i][i_layer][i_node - 1])\n",
    "                    if i < len(input_data) - 1:\n",
    "                        temp += \", \"\n",
    "                title.append(temp)\n",
    "            value.append(SIZE)\n",
    "            x.append(x_val)\n",
    "            y.append(y_val)\n",
    "            y_val += YSTEP\n",
    "            nodes.append(node_i)\n",
    "            node_i += 1\n",
    "        x_val += XSTEP\n",
    "\n",
    "        idx += 1\n",
    "        for origin in range(n_curr + 1):\n",
    "            dst_idx = -1\n",
    "            for w in reversed(data[idx].split()):\n",
    "                edge.append((nodes[src_idx], nodes[dst_idx], w))\n",
    "                dst_idx -= 1\n",
    "            src_idx += 1\n",
    "            idx += 1\n",
    "\n",
    "    g = Network(notebook=True, cdn_resources=\"remote\")\n",
    "    g.add_nodes(nodes,title = title,value = value,x=x,y=y,label = label,color = color)\n",
    "\n",
    "    for e in edge:\n",
    "        g.add_edge(e[0], e[1], title = e[2], color=\"#162347\")\n",
    "\n",
    "    for n in g.nodes:\n",
    "        n.update({'physics': False})\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize using Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = visualize_network(data, complete_out)\n",
    "g.show(\"./tmp/network.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (3,) and (2,2) not aligned: 3 (dim 0) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1212/753813426.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1212/255828213.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x_train, y_train, learning_rate, epochs, batch_size, err_threshold)\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m                     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[1;31m# compute loss (for display purpose only)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_1212/963391821.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (3,) and (2,2) not aligned: 3 (dim 0) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "net.fit(x_train, out_true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation Section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Output** Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delta_output(out_pred, out_true, predecessor_out, act_type):\n",
    "    dE_dO = -(out_true - out_pred)\n",
    "    dO_dNet = None\n",
    "    dNet_dW = predecessor_out\n",
    "\n",
    "    if act_type == 0: #linear\n",
    "        dO_dNet = 1\n",
    "    elif act_type == 1: #relu\n",
    "        dO_dNet = np.where(out_pred < 0, 0, 1)\n",
    "    elif act_type == 2: #sigmoid\n",
    "        dO_dNet = out_pred * (1 - out_pred)\n",
    "\n",
    "    dE_dNet = dE_dO * dO_dNet\n",
    "    if act_type == 3: # softmax\n",
    "        dE_dNet = np.where(out_pred == out_true, out_pred, -(1 - out_pred))\n",
    "    \n",
    "    delta = []\n",
    "    for i in dNet_dW: # TODO: Change for batch\n",
    "        cur_w = []\n",
    "        for j in dE_dNet:\n",
    "            cur_w.append(i * j)\n",
    "        delta.append(cur_w)\n",
    "    \n",
    "    return delta, dE_dNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Hidden** Delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_succ(succ_dE_dNet,weight):\n",
    "    err_total = []\n",
    "    for w in weight[1:]:  # skip the bias\n",
    "        err_total.append(np.sum(succ_dE_dNet * np.array(w)))\n",
    "    \n",
    "    return err_total\n",
    "\n",
    "def delta_hidden(predecessor_out, succ_out, succ_dE_dNet, succ_weight, act_type):\n",
    "    dEtotal_dH = error_succ(succ_dE_dNet, succ_weight)\n",
    "    dH_dNet = None\n",
    "    dNet_dW = predecessor_out\n",
    "\n",
    "    if act_type == 0: #linear\n",
    "        dH_dNet = 1\n",
    "    elif act_type == 1: #relu\n",
    "        dH_dNet = np.where(succ_out < 0, 0, 1)\n",
    "    elif act_type == 2: #sigmoid\n",
    "        dH_dNet = succ_out * (1 - succ_out)\n",
    "\n",
    "    dEtotal_dNet = dEtotal_dH * dH_dNet\n",
    "    # if act_type == 3: #softmax\n",
    "    #     dEtotal_dNet = np.where(prev_out == out_true, prev_out, -(1 - prev_out))\n",
    "\n",
    "    delta = []\n",
    "    for i in dNet_dW.flatten(): # TODO: change for batch\n",
    "        cur_w = []\n",
    "        for j in dEtotal_dNet:\n",
    "            cur_w.append(i * j)\n",
    "        delta.append(cur_w)\n",
    "    return delta, dEtotal_dNet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Update** Weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(weights, deltas, learning_rate):\n",
    "    np_weights = np.array(weights) - learning_rate * np.array(deltas)\n",
    "    return np_weights.tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Iteration Implementation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "total deltas (gradient) for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output deltas computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pred, out_true, _, _ = compute_out_and_errors(output_data, out)\n",
    "\n",
    "# Without bias TODO: change for batch\n",
    "predecessor_out = np.array([i[-2] for i in complete_out]).flatten()\n",
    "# Concatenate with bias TODO : change for batch\n",
    "predecessor_out = np.concatenate((np.array([1]), predecessor_out))\n",
    "\n",
    "delta, succ_dE_dNet = delta_output(out_pred, out_true, predecessor_out, 2)\n",
    "deltas.append(delta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hidden deltas computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "succ_out = np.array([i[-2] for i in complete_out]).flatten()\n",
    "delta, succ_dE_dNet = delta_hidden(x_train, succ_out, succ_dE_dNet, weights[-1], 2)\n",
    "deltas.append(delta)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = update(weights, deltas[::-1], 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.34196709387931556, 0.3407865766027151],\n",
       "  [0.14959835469396576, 0.24953932883013577],\n",
       "  [0.19919670938793158, 0.29907865766027153]],\n",
       " [[0.461501438371443, 0.6380982365165563],\n",
       "  [0.3178329594357693, 0.522602540477475],\n",
       "  [0.3673323721524668, 0.5727402422159782]]]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
