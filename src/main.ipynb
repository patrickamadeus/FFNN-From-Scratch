{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FFNN - BackPropagation\n",
    "1. Add input in /test/input and model in /test/model with .txt format, makesure they both have the same filename.\n",
    "2. Input the filename for both the input and the model, ensuring that they have the same filename.\n",
    "3. Scroll down and click on `./tmp/network.html`. This will redirect you to network.html, which you can then open the visualization using a live server.\n",
    "\n",
    "#### Made by:\n",
    "- Samuel Christoper Swandi - 13520075\n",
    "- Grace Claudia - 13520078\n",
    "- Ubaidillah Ariq Prathama - 13520085\n",
    "- Patrick Amadeus Irawan - 13520109\n",
    "\n",
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of Content\n",
    "\n",
    "1. [Library & Dependencies](#library)\n",
    "2. [Helper Function](#helper)\n",
    "3. [Neural Network Visualization](#visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library & Dependencies <a name=\"library\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 -m pip install pyvis==0.3.2\n",
    "!python3 -m pip install networkx==2.6.3\n",
    "!python3 -m pip install numpy==1.21.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pandas import DataFrame\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import os\n",
    "\n",
    "from pyvis.network import Network"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConnectedLayer:\n",
    "    def __init__(self, input_size, output_size, weights):\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.weights = weights[1:]\n",
    "        self.bias = weights[0]\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return np.dot(input, self.weights) + self.bias"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationLayer:\n",
    "    def __init__(self, activation):\n",
    "        self.activation = activation\n",
    "    \n",
    "    def forward(self, input):\n",
    "        self.input = input\n",
    "        return self.activation(input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        self.layers = []\n",
    "\n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    def predict(self, input_data):\n",
    "        samples = len(input_data)\n",
    "        complete_result = []\n",
    "        result = []\n",
    "        output = input_data[:, 1:]\n",
    "\n",
    "        for layer in self.layers:\n",
    "            output = layer.forward(output)\n",
    "            if isinstance(layer, ActivationLayer):\n",
    "                complete_result.append(output)\n",
    "\n",
    "        return complete_result[-1] , complete_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Helper** Function <a class=\"anchor\" id=\"helper\"></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear(net):\n",
    "    return net\n",
    "\n",
    "def ReLU(net):\n",
    "    return np.maximum(0,net)\n",
    "\n",
    "def sigmoid(net):\n",
    "    return 1/(1+np.exp(-net))\n",
    "\n",
    "def softmax(net):\n",
    "    res = []\n",
    "    for sample in net:\n",
    "        res.append(np.exp(sample)/np.sum(np.exp(sample)))\n",
    "    return np.array(res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_true, y_pred):\n",
    "    return np.mean(np.square(y_true - y_pred))\n",
    "\n",
    "def sse(y_true, y_pred):\n",
    "    return np.sum(np.square(y_true - y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_load(data):\n",
    "    '''\n",
    "    Function to load model from file\n",
    "    INPUT :     data -> data from model file\n",
    "\n",
    "    OUTPUT :    weights -> weights of each model neuron\n",
    "                list_prev_size -> list of previous layer size\n",
    "                list_layer_size -> list of current layer size\n",
    "                list_activation -> list of activation function\n",
    "    '''\n",
    "\n",
    "    idx = 1\n",
    "    weights,list_prev_size,list_layer_size,list_activation = [],[],[],[]\n",
    "\n",
    "    for i in range(int(data[0]) - 1):\n",
    "        # Loading size & act function\n",
    "        prev_size, layer_size, activation = [int(i) for i in data[idx].split()]\n",
    "        list_prev_size.append(prev_size)\n",
    "        list_layer_size.append(layer_size)\n",
    "        list_activation.append(activation)\n",
    "        \n",
    "        # Loading weights\n",
    "        idx += 1\n",
    "        weight = []\n",
    "        for j in range(prev_size + 1):\n",
    "            weight.append([float(i) for i in data[idx].split()])\n",
    "            idx += 1\n",
    "        weights.append(weight)\n",
    "    \n",
    "    return weights, list_prev_size, list_layer_size, list_activation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict Output Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_output(input_data, n, weights, list_prev_size, list_layer_size, list_activation):\n",
    "    '''\n",
    "    Function to predict output from input data\n",
    "    INPUT :     input_data -> input data from input file\n",
    "                n -> number of layers\n",
    "                weights -> weights of each model neuron, obtained from model_load function\n",
    "                list_prev_size -> list of previous layer size, obtained from model_load function\n",
    "                list_layer_size -> list of current layer size, obtained from model_load function\n",
    "                list_activation -> list of activation function, obtained from model_load function\n",
    "\n",
    "    OUTPUT :    out -> output of the model\n",
    "                complete_out -> complete output of the model, visualization purpose\n",
    "                x_train -> input data, visualization purpose\n",
    "    '''\n",
    "    # Assign x_train from input_data\n",
    "    x_train = []\n",
    "    for i in range(len(input_data)):\n",
    "        x_train.append([float(i) for i in input_data[i].split()])\n",
    "    x_train = np.array(x_train)\n",
    "    \n",
    "    # Build NN model\n",
    "    act = {0: linear, 1: ReLU, 2: sigmoid, 3: softmax}\n",
    "    net = NeuralNetwork()\n",
    "    for i in range (n - 1):\n",
    "        net.add(ConnectedLayer(list_prev_size[i], list_layer_size[i], weights[i]))\n",
    "        net.add(ActivationLayer(act[list_activation[i]]))\n",
    "    \n",
    "    # Predict output\n",
    "    out, complete_out = net.predict(x_train)\n",
    "\n",
    "    # Gather complete output\n",
    "    n_complete_out = []\n",
    "    for i in range(len(complete_out[0])):\n",
    "        n_complete_out.append([complete_out[0][i], complete_out[-1][i]])\n",
    "\n",
    "    complete_out = n_complete_out\n",
    "    return out, complete_out, x_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSE Errors Function + microhelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_out_and_errors(output_data, out):\n",
    "    '''\n",
    "    Function to calculate output error\n",
    "    INPUT :     output_data -> output data from output file\n",
    "                out -> output of the model, obtained from predict_output function\n",
    "\n",
    "    OUTPUT :    out_pred -> output of the model (flattened)\n",
    "                out_true -> output from output_data (flattened)\n",
    "                sse_error -> sum squared error\n",
    "                sse_error <= max_sse -> boolean value, True if sse_error <= max_sse, False otherwise\n",
    "    '''\n",
    "    # Assign y_train from output_data\n",
    "    parsed_output = [[float(j) for j in i.split()] for i in output_data]\n",
    "    out_pred = out.flatten()\n",
    "    out_true = np.array(parsed_output[:-1]).flatten()\n",
    "    max_sse = parsed_output[-1][0]\n",
    "\n",
    "    return out_pred, out_true, sse(out_true, out_pred), sse(out_true, out_pred) <= max_sse"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Load** Section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FOLDER = '../test/model/'\n",
    "INPUT_FOLDER = '../test/input/'\n",
    "OUTPUT_FOLDER = '../test/output/'\n",
    "# read file from test folder\n",
    "def read_file(folder_path, file_name):\n",
    "    with open(folder_path + file_name, 'r') as file:\n",
    "        data = [i.rstrip(\"\\n\") for i in file.readlines()]\n",
    "    return data\n",
    "\n",
    "filename = input('Enter test case name (with extension): ')\n",
    "data = read_file(MODEL_FOLDER, filename)\n",
    "input_data = read_file(INPUT_FOLDER, filename)\n",
    "\n",
    "try: \n",
    "    output_data = read_file(OUTPUT_FOLDER, filename)\n",
    "except:\n",
    "    output_data = None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Model Information---\n",
      "Number of layers : 3\n",
      "Input size : 2\n",
      "Output size : 1\n",
      "\n",
      "Weights : [[[0.25, 0.25], [0.25, 0.25], [0.25, 0.25]], [[0.0], [0.25], [0.25]]]\n",
      "Previous layer size : [2, 2]\n",
      "Current layer size : [2, 1]\n",
      "Activation function : [2, 2]\n"
     ]
    }
   ],
   "source": [
    "weights, list_prev_size, list_layer_size, list_activation = model_load(data)\n",
    "\n",
    "print('---Model Information---')\n",
    "print('Number of layers :', len(list_prev_size) + 1)\n",
    "print('Input size :', list_prev_size[0])\n",
    "print('Output size :', list_layer_size[-1])\n",
    "\n",
    "print()\n",
    "print('Weights :', weights)\n",
    "print('Previous layer size :', list_prev_size)\n",
    "print('Current layer size :', list_layer_size)\n",
    "print('Activation function :', list_activation)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Predict** Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Prediction Information---\n",
      "Input data : ['1 1.0 1.0', '1 1.0 -1.0', '1 -1.0 1.0', '1 -1.0 -1.0']\n",
      "Output data : [0.58409077 0.569813   0.569813   0.55451042]\n"
     ]
    }
   ],
   "source": [
    "out, complete_out, x_train = predict_output(input_data, int(data[0]), weights, list_prev_size, list_layer_size, list_activation)\n",
    "\n",
    "# Print the information, complete with brief verbose\n",
    "print('---Prediction Information---')\n",
    "print('Input data :', input_data)\n",
    "print('Output data :', out.flatten())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Error with **Sum Squared Error (SSE)**\n",
    "\n",
    "Sum Squared Error (SSE) is a mathematical function used in statistics and machine learning to measure the difference between predicted and actual values. It is commonly used as a cost function in various optimization algorithms, such as gradient descent.\n",
    "\n",
    "The SSE is calculated by taking the difference between each predicted value and its corresponding actual value, squaring the difference, and then summing all of the squared differences:\n",
    "\n",
    "$$SSE = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "Where:\n",
    "- $n$ is the number of data points\n",
    "- $y_i$ is the actual value of the i-th data point\n",
    "- $\\hat{y}_i$ is the predicted value of the i-th data point\n",
    "\n",
    "The SSE gives an indication of how well the model fits the data. A lower SSE indicates that the model is a better fit for the data.\n",
    "\n",
    "In machine learning, the SSE is often used as a cost function to be minimized during training of a model. The goal is to find the set of model parameters that minimizes the SSE, thus improving the accuracy of the model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output prediction : [0.58409077 0.569813   0.569813   0.55451042]\n",
      "Output true : [ 1. -1. -1.  1.]\n",
      "SSE  :  5.300067181259587\n",
      "sse <= max_sse  : False\n"
     ]
    }
   ],
   "source": [
    "out_pred, out_true, sse_err, isLessThanMaxSSE = compute_out_and_errors(output_data, out)\n",
    "\n",
    "print('Output prediction :', out_pred)\n",
    "print('Output true :', out_true)\n",
    "print('SSE  : ', sse_err)\n",
    "print(\"sse <= max_sse  :\", isLessThanMaxSSE)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Visualization with **Pyvis**\n",
    "\n",
    "Pyvis is a Python library that provides an easy-to-use interface for visualizing complex networks, including neural networks. Implementation of the visualization is enlisted below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_network(data, complete_out) -> Network:\n",
    "    n = int(data[0])\n",
    "\n",
    "    # Constant\n",
    "    XSTEP, YSTEP, SIZE = 300, 300, 10\n",
    "    ACT = {0: \"linear\", 1: \"ReLU\", 2: \"sigmoid\", 3: \"softmax\"}\n",
    "\n",
    "    # Nodes\n",
    "    nodes = []\n",
    "    node_i = 1\n",
    "\n",
    "    # Nodes Value\n",
    "    value = []\n",
    "    x_val = 0\n",
    "    y_val = 0\n",
    "\n",
    "    # Position\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    # Styling + Text\n",
    "    label = []\n",
    "    color = []\n",
    "    edge = []\n",
    "    title = []\n",
    "\n",
    "    # Indexing\n",
    "    src_idx = 0\n",
    "    idx = 1\n",
    "\n",
    "    for i_layer in range(n - 1):\n",
    "        n_curr, n_next, ACT = [int(i) for i in data[idx].split()]\n",
    "\n",
    "        if i_layer == 0:  # means that this is the first layer, hence construct input\n",
    "            for i_node in range(n_curr + 1):\n",
    "                if i_node == 0:  # bias\n",
    "                    color.append(\"#dd4b39\")\n",
    "                    label.append(\"Input[bias]\")\n",
    "                    temp = \"\"\n",
    "                    for i in range (len(input_data)):\n",
    "                        temp += str(x_train[i][0])\n",
    "                        if i < len(input_data) - 1:\n",
    "                            temp += \", \"\n",
    "                    title.append(temp)\n",
    "                else:\n",
    "                    color.append(\"#162347\")\n",
    "                    label.append(\"Input[{}]\".format(i_node))\n",
    "                    temp = \"\"\n",
    "                    for i in range (len(input_data)):\n",
    "                        temp += str(x_train[i][i_node])\n",
    "                        if i < len(input_data) - 1:\n",
    "                            temp += \", \"\n",
    "                    title.append(temp)\n",
    "                value.append(SIZE)\n",
    "                x.append(x_val)\n",
    "                y.append(y_val)\n",
    "                y_val += YSTEP\n",
    "                nodes.append(node_i)\n",
    "                node_i += 1\n",
    "            x_val += XSTEP\n",
    "\n",
    "        y_val = 0\n",
    "        # always construct the next layer\n",
    "        for i_node in range(n_next + 1):\n",
    "            if i_node == 0:\n",
    "                if i_layer == n - 2:\n",
    "                    continue\n",
    "                color.append(\"#dd4b39\")\n",
    "                label.append(\"HL{}[bias]\".format(i_layer + 1))\n",
    "                temp = \"\"\n",
    "                for i in range (len(input_data)):\n",
    "                    temp +=  \"1\"\n",
    "                    if i < len(input_data) - 1:\n",
    "                        temp += \", \"\n",
    "                title.append(temp)\n",
    "            else:\n",
    "                color.append(\"#162347\")\n",
    "                if i_layer == n - 2:\n",
    "                    label.append(\"Output[{}]\".format(i_node))\n",
    "                else:\n",
    "                    label.append(\"HL{}[{}]\".format(i_layer + 1, i_node))\n",
    "                temp = \"\"\n",
    "                for i in range (len(input_data)):\n",
    "                    temp += str(complete_out[i][i_layer][i_node - 1])\n",
    "                    if i < len(input_data) - 1:\n",
    "                        temp += \", \"\n",
    "                title.append(temp)\n",
    "            value.append(SIZE)\n",
    "            x.append(x_val)\n",
    "            y.append(y_val)\n",
    "            y_val += YSTEP\n",
    "            nodes.append(node_i)\n",
    "            node_i += 1\n",
    "        x_val += XSTEP\n",
    "\n",
    "        idx += 1\n",
    "        for origin in range(n_curr + 1):\n",
    "            dst_idx = -1\n",
    "            for w in reversed(data[idx].split()):\n",
    "                edge.append((nodes[src_idx], nodes[dst_idx], w))\n",
    "                dst_idx -= 1\n",
    "            src_idx += 1\n",
    "            idx += 1\n",
    "\n",
    "    g = Network(notebook=True, cdn_resources=\"remote\")\n",
    "    g.add_nodes(nodes,title = title,value = value,x=x,y=y,label = label,color = color)\n",
    "\n",
    "    for e in edge:\n",
    "        g.add_edge(e[0], e[1], title = e[2], color=\"#162347\")\n",
    "\n",
    "    for n in g.nodes:\n",
    "        n.update({'physics': False})\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize using Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = visualize_network(data, complete_out)\n",
    "g.show(\"./tmp/network.html\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_output(out_pred, out_true):\n",
    "\n",
    "    # TODO non-sigmoid\n",
    "    return out_pred * (1 - out_pred) * (out_true - out_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10103631, -0.38480221, -0.38480221,  0.11004867])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_pred, out_true, _, _ = compute_out_and_errors(output_data, out)\n",
    "\n",
    "error_output(out_pred, out_true)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
